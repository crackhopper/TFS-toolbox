{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# default initialize with Xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10. loss 5.095845, score:0.469300\n",
      "step 20. loss 0.874589, score:0.730200\n",
      "step 30. loss 0.746855, score:0.850000\n",
      "step 40. loss 0.287814, score:0.894800\n",
      "step 50. loss 0.409828, score:0.919200\n",
      "step 60. loss 0.286020, score:0.931500\n",
      "step 70. loss 0.237745, score:0.944100\n",
      "step 80. loss 0.225911, score:0.948500\n",
      "step 90. loss 0.147063, score:0.951200\n",
      "step 100. loss 0.213493, score:0.955900\n",
      "step 110. loss 0.118846, score:0.958300\n",
      "step 120. loss 0.145289, score:0.959900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tfs.models.lenet.LeNet at 0x103f2e7d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tfs.models import LeNet\n",
    "net = LeNet()\n",
    "from tfs.dataset import Mnist\n",
    "dataset = Mnist()\n",
    "net.build()\n",
    "net.fit(dataset,batchsize,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSUV initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tfs.core.initializer import Initializer,InitType\n",
    "from tfs.core.layer import *\n",
    "import numpy as np\n",
    "\n",
    "def svd_orthonormal(shape):\n",
    "    if len(shape) < 2:\n",
    "        raise RuntimeError(\"Only shapes of length 2 or more are supported.\")\n",
    "    flat_shape = (shape[0], np.prod(shape[1:]))\n",
    "    a = np.random.standard_normal(flat_shape)\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    q = u if u.shape == flat_shape else v\n",
    "    q = q.reshape(shape)\n",
    "    return q\n",
    "\n",
    "# this initializer would also change the weight of current net.\n",
    "class LSUV(Initializer):\n",
    "    ret_type = InitType.values\n",
    "    available_node_type = [Conv2d, FullyConnect]\n",
    "    def __init__(\n",
    "        self,\n",
    "        net,\n",
    "        batchX,\n",
    "        print_names=[]\n",
    "    ):\n",
    "        vs = locals()\n",
    "        net = vs['net']\n",
    "        del vs['self']\n",
    "        del vs['net']\n",
    "        super(LSUV,self).__init__(net,**vs)\n",
    "        \n",
    "    def _build_init_table(self):\n",
    "        tbl = {}\n",
    "        margin = 0.1\n",
    "        max_iter = 10\n",
    "        for n in self.net.net_def:\n",
    "            print(type(n).__name__)\n",
    "            if type(n) not in self.available_node_type:\n",
    "                continue\n",
    "            my_dict = {}\n",
    "            \n",
    "            name = 'weights'\n",
    "            v = n.variables[name]\n",
    "            defaultInitOp = n.initializers[name]\n",
    "            val = defaultInitOp(v.get_shape().as_list(),v.dtype.base_dtype)\n",
    "            myval = svd_orthonormal(val.shape)\n",
    "            my_dict[name] = myval\n",
    "            \n",
    "            name = 'biases'\n",
    "            v = n.variables[name]\n",
    "            defaultInitOp = n.initializers[name]\n",
    "            val = defaultInitOp(v.get_shape().as_list(),v.dtype.base_dtype)\n",
    "            myval = val\n",
    "            my_dict[name] = myval\n",
    "            \n",
    "            n.set_weights(my_dict)\n",
    "            \n",
    "            acts1 = self.net.eval_node(n,self.param.batchX)\n",
    "            var1=np.var(acts1)\n",
    "            iter1=0\n",
    "            needed_variance = 1.0\n",
    "            print(var1)\n",
    "            \n",
    "            while (abs(needed_variance - var1) > margin):\n",
    "                weights = self.net.run(n.variables['weights'])\n",
    "                biases = self.net.run(n.variables['biases'])\n",
    "                weights /= np.sqrt(var1)/np.sqrt(needed_variance)\n",
    "                w_all_new = {'weights':weights,\n",
    "                             'biases':biases}\n",
    "                n.set_weights(w_all_new)\n",
    "                acts1=self.net.eval_node(n,self.param.batchX)\n",
    "                var1=np.var(acts1)\n",
    "                iter1+=1\n",
    "                print(var1)\n",
    "                if iter1 > max_iter:\n",
    "                    break            \n",
    "\n",
    "        # it is initialized during the loop, so we can return a nil tbl\n",
    "        return tbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tfs.models import LeNet\n",
    "net = LeNet()\n",
    "from tfs.dataset import Mnist\n",
    "dataset = Mnist()\n",
    "batchX,batchY = dataset.train.next_batch(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.initializer = LSUV(net,batchX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d\n",
      "1914.37\n",
      "0.999999\n",
      "MaxPool\n",
      "Conv2d\n",
      "0.0713312\n",
      "0.829\n",
      "0.993449\n",
      "MaxPool\n",
      "FullyConnect\n",
      "1.06592\n",
      "FullyConnect\n",
      "0.547299\n",
      "1.0\n",
      "Softmax\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'prob:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.build() # the number represent the variances that we adjust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10. loss 1.484214, score:0.448000\n",
      "step 20. loss 0.418603, score:0.858700\n",
      "step 30. loss 0.444055, score:0.914200\n",
      "step 40. loss 0.159206, score:0.936500\n",
      "step 50. loss 0.249291, score:0.948700\n",
      "step 60. loss 0.145562, score:0.956900\n",
      "step 70. loss 0.160076, score:0.963000\n",
      "step 80. loss 0.126397, score:0.965900\n",
      "step 90. loss 0.095292, score:0.968800\n",
      "step 100. loss 0.135110, score:0.970500\n",
      "step 110. loss 0.098984, score:0.972600\n",
      "step 120. loss 0.128667, score:0.971900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tfs.models.lenet.LeNet at 0x1192c1fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(dataset,batchsize,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
