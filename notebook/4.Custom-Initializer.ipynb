{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# default initialize with Xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10. loss 5.903676, test accuracy:0.430100\n",
      "step 20. loss 0.979873, test accuracy:0.655800\n",
      "step 30. loss 0.708969, test accuracy:0.818600\n",
      "step 40. loss 0.391821, test accuracy:0.876600\n",
      "step 50. loss 0.339591, test accuracy:0.909400\n",
      "step 60. loss 0.312280, test accuracy:0.926600\n",
      "step 70. loss 0.286118, test accuracy:0.934600\n",
      "step 80. loss 0.252523, test accuracy:0.945900\n",
      "step 90. loss 0.170250, test accuracy:0.944600\n",
      "step 100. loss 0.289807, test accuracy:0.953600\n",
      "step 110. loss 0.134003, test accuracy:0.955100\n",
      "step 120. loss 0.192019, test accuracy:0.957100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tfs.models.lenet.LeNet at 0x103e0af50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tfs.models import LeNet\n",
    "net = LeNet()\n",
    "from tfs.dataset import Mnist\n",
    "dataset = Mnist()\n",
    "net.build()\n",
    "net.fit(dataset,batchsize,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSUV initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tfs.core.initializer import Initializer,InitType\n",
    "from tfs.core.layer import *\n",
    "import numpy as np\n",
    "\n",
    "def svd_orthonormal(shape):\n",
    "    if len(shape) < 2:\n",
    "        raise RuntimeError(\"Only shapes of length 2 or more are supported.\")\n",
    "    flat_shape = (shape[0], np.prod(shape[1:]))\n",
    "    a = np.random.standard_normal(flat_shape)\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    q = u if u.shape == flat_shape else v\n",
    "    q = q.reshape(shape)\n",
    "    return q\n",
    "\n",
    "# this initializer would also change the weight of current net.\n",
    "class LSUV(Initializer):\n",
    "    ret_type = InitType.values\n",
    "    available_node_type = [Conv2d, FullyConnect]\n",
    "    def __init__(\n",
    "        self,\n",
    "        net,\n",
    "        batchX,\n",
    "        print_names=[]\n",
    "    ):\n",
    "        vs = locals()\n",
    "        net = vs['net']\n",
    "        del vs['self']\n",
    "        del vs['net']\n",
    "        super(LSUV,self).__init__(net,**vs)\n",
    "        \n",
    "    def _build_init_table(self):\n",
    "        tbl = {}\n",
    "        margin = 0.1\n",
    "        max_iter = 10\n",
    "        for n in self.net.net_def:\n",
    "            print(type(n).__name__)\n",
    "            if type(n) not in self.available_node_type:\n",
    "                continue\n",
    "            my_dict = {}\n",
    "            \n",
    "            name = 'weights'\n",
    "            v = n.variables[name]\n",
    "            defaultInitOp = n.initializers[name]\n",
    "            val = defaultInitOp(v.get_shape().as_list(),v.dtype.base_dtype)\n",
    "            myval = svd_orthonormal(val.shape)\n",
    "            my_dict[name] = myval\n",
    "            \n",
    "            name = 'biases'\n",
    "            v = n.variables[name]\n",
    "            defaultInitOp = n.initializers[name]\n",
    "            val = defaultInitOp(v.get_shape().as_list(),v.dtype.base_dtype)\n",
    "            myval = val\n",
    "            my_dict[name] = myval\n",
    "            \n",
    "            n.set_weights(my_dict)\n",
    "            \n",
    "            acts1 = self.net.eval_node(n,self.param.batchX)\n",
    "            var1=np.var(acts1)\n",
    "            iter1=0\n",
    "            needed_variance = 1.0\n",
    "            print(var1)\n",
    "            \n",
    "            while (abs(needed_variance - var1) > margin):\n",
    "                weights = self.net.run(n.variables['weights'])\n",
    "                biases = self.net.run(n.variables['biases'])\n",
    "                weights /= np.sqrt(var1)/np.sqrt(needed_variance)\n",
    "                w_all_new = {'weights':weights,\n",
    "                             'biases':biases}\n",
    "                n.set_weights(w_all_new)\n",
    "                acts1=self.net.eval_node(n,self.param.batchX)\n",
    "                var1=np.var(acts1)\n",
    "                iter1+=1\n",
    "                print(var1)\n",
    "                if iter1 > max_iter:\n",
    "                    break            \n",
    "\n",
    "        # it is initialized during the loop, so we can return a nil tbl\n",
    "        return tbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tfs.models import LeNet\n",
    "net = LeNet()\n",
    "from tfs.dataset import Mnist\n",
    "dataset = Mnist()\n",
    "batchX,batchY = dataset.train.next_batch(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.initializer = LSUV(net,batchX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d\n",
      "2111.35\n",
      "1.0\n",
      "MaxPool\n",
      "Conv2d\n",
      "0.0835624\n",
      "0.849939\n",
      "0.994472\n",
      "MaxPool\n",
      "FullyConnect\n",
      "1.00148\n",
      "FullyConnect\n",
      "2.31459\n",
      "1.0\n",
      "Softmax\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'prob:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10. loss 0.455967, test accuracy:0.850200\n",
      "step 20. loss 0.275849, test accuracy:0.918300\n",
      "step 30. loss 0.293066, test accuracy:0.941500\n",
      "step 40. loss 0.110870, test accuracy:0.955700\n",
      "step 50. loss 0.161958, test accuracy:0.962900\n",
      "step 60. loss 0.101815, test accuracy:0.968700\n",
      "step 70. loss 0.136306, test accuracy:0.973900\n",
      "step 80. loss 0.066778, test accuracy:0.972000\n",
      "step 90. loss 0.059173, test accuracy:0.975000\n",
      "step 100. loss 0.143145, test accuracy:0.976200\n",
      "step 110. loss 0.064761, test accuracy:0.977400\n",
      "step 120. loss 0.117925, test accuracy:0.976600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tfs.models.lenet.LeNet at 0x112cbcbd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(dataset,batchsize,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
